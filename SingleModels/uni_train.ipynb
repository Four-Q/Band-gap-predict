{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train All Single Models\n",
    "1. Linear Regression\n",
    "   - Elastic Net\n",
    "   - Ridge\n",
    "   - Lasso\n",
    "2. Boosting Decision Trees\n",
    "   - GBR\n",
    "   - LightGBM\n",
    "   - XGBoostRegressor (the optimization version of GBDT by using L1/L2 regularization.)\n",
    "3. RandomForest\n",
    "   - RandomForest(RF)\n",
    "   - ExtremeRandomTrees(ERT)\n",
    "4. Kernel Ridge Regression(KRR)\n",
    "5. K-Nearest Neighbor(KNN)\n",
    "6. Support Vector Regressor(SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the custom module from a specific path\n",
    "sys.path.insert(0, os.path.join(current_path, '../'))\n",
    "# Importing the custom module\n",
    "from Utools.draw import plot_feature_importance, plot_feature_importance\n",
    "from Utools.SingleModel import SingleModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "# Import sklearn models\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_dir = os.path.join(current_path, '../Data/composition_data/feature_data')\n",
    "# dft data\n",
    "dft_train = pd.read_csv(os.path.join(file_dir, 'dft', 'train.csv'))\n",
    "dft_test = pd.read_csv(os.path.join(file_dir, 'dft', 'test.csv'))\n",
    "# exp data\n",
    "exp_train = pd.read_csv(os.path.join(file_dir, 'exp', 'train.csv'))\n",
    "exp_test = pd.read_csv(os.path.join(file_dir, 'exp', 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_train_X = dft_train.drop(columns=['composition', 'band_gap'])\n",
    "dft_train_y = dft_train['band_gap']\n",
    "exp_train_X = exp_train.drop(columns=['composition', 'band_gap'])\n",
    "exp_train_y = exp_train['band_gap']\n",
    "dft_test_X = dft_test.drop(columns=['composition', 'band_gap'])\n",
    "dft_test_y = dft_test['band_gap']\n",
    "exp_test_X = exp_test.drop(columns=['composition', 'band_gap'])\n",
    "exp_test_y = exp_test['band_gap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model performance as df\n",
    "metrics_df = pd.DataFrame(columns=['Model', 'Train_set', 'Test_set', 'R²', 'RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # Linear models\n",
    "    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=RANDOM_SEED),\n",
    "    'Ridge': Ridge(alpha=0.1, random_state=RANDOM_SEED),\n",
    "    'Lasso': Lasso(alpha=0.1, random_state=RANDOM_SEED), \n",
    "    # GBDT models\n",
    "    'GBR': GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_features='sqrt', random_state=RANDOM_SEED),   \n",
    "    'LightGBM': LGBMRegressor(objective='regression', n_estimators=500, learning_rate=0.05, \n",
    "                              reg_alpha=0.1, reg_lambda=0.1, max_depth=-1, random_state=RANDOM_SEED),\n",
    "    'XGBoost': XGBRegressor(objective='reg:squarederror',n_estimators=500, learning_rate=0.1, max_depth=4, random_state=RANDOM_SEED),\n",
    "    # Random Forest models\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=500, max_depth=None, max_features=0.25, random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    'ExtraRandomTrees': ExtraTreesRegressor(n_estimators=500, max_depth=None, max_features=0.25, random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    'KernelRidge': Pipeline([\n",
    "    ('nystroem', Nystroem(kernel='rbf',  n_components=8000, random_state=RANDOM_SEED)),\n",
    "    ('ridge', Ridge(alpha=1.0))]),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=10, weights='uniform', algorithm='auto', n_jobs=-1),\n",
    "    # SVM models\n",
    "    'SVR': SVR(kernel='rbf', C=25, epsilon=0.07, gamma=0.01)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number = 0\n",
    "model_nums = len(models)\n",
    "# Loop through each model\n",
    "for model_name, model in models.items():\n",
    "    model_number += 1\n",
    "    # Create directories for saving models and figures\n",
    "    file_path = os.path.join(current_path, model_name)\n",
    "    fig_path = os.path.join(file_path, 'figures')\n",
    "    model_path = os.path.join(file_path, 'model')\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(file_path, exist_ok=True)\n",
    "    os.makedirs(fig_path, exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    # record model metrics\n",
    "    model_metrics = pd.DataFrame(columns=['Model', 'Train_set', 'Test_set', 'R²', 'RMSE', 'MAE'])\n",
    "    # Train the model on dft data\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"[{model_number}/{model_nums} - DFT - {model_name}] Training {model_name} on DFT data:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    dft_model = SingleModel(clone(model), random_state=RANDOM_SEED)\n",
    "    dft_model.train(dft_train_X, dft_train_y)\n",
    "    # evaluate on the dft test set\n",
    "    print(f\"Evaluating DFT {model_name} on DFT test set:\")\n",
    "    \n",
    "    metrics = dft_model.evaluate(dft_test_X, dft_test_y, fig_path=os.path.join(fig_path, 'dft_train_dft_test.png'))\n",
    "    model_metrics.loc[len(model_metrics)] = {\n",
    "    'Model': model_name,\n",
    "    'Train_set': 'dft',\n",
    "    'Test_set': 'dft',\n",
    "    'R²': metrics['r2'],\n",
    "    'RMSE': metrics['rmse'],\n",
    "    'MAE': metrics['mae']\n",
    "}\n",
    "    # evaluate on the exp test set\n",
    "    print(f\"Evaluating DFT {model_name} on EXP test set:\")\n",
    "    metrics = dft_model.evaluate(exp_test_X, exp_test_y, fig_path=os.path.join(fig_path, 'dft_train_exp_test.png'))\n",
    "    model_metrics.loc[len(model_metrics)] = {\n",
    "    'Model': model_name,\n",
    "    'Train_set': 'dft',\n",
    "    'Test_set': 'exp',\n",
    "    'R²': metrics['r2'],\n",
    "    'RMSE': metrics['rmse'],\n",
    "    'MAE': metrics['mae']\n",
    "}\n",
    "    ################################################\n",
    "    # Train the model on exp data\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"[{model_number}/{model_nums} - EXP - {model_name}] Training {model_name} on EXP data:\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    exp_model = SingleModel(clone(model), random_state=RANDOM_SEED)\n",
    "    exp_model.train(exp_train_X, exp_train_y)\n",
    "    # evaluate on the exp test set\n",
    "    print(f\"Evaluating EXP {model_name} on EXP test set:\")\n",
    "    metrics = exp_model.evaluate(exp_test_X, exp_test_y, fig_path=os.path.join(fig_path, 'exp_train_exp_test.png'))\n",
    "    model_metrics.loc[len(model_metrics)] = {\n",
    "    'Model': model_name,\n",
    "    'Train_set': 'exp',\n",
    "    'Test_set': 'exp',\n",
    "    'R²': metrics['r2'],\n",
    "    'RMSE': metrics['rmse'],\n",
    "    'MAE': metrics['mae']\n",
    "}\n",
    "    # evaluate on the dft test set\n",
    "    print(f\"Evaluating EXP {model_name} on DFT test set:\")\n",
    "    metrics = exp_model.evaluate(dft_test_X, dft_test_y, fig_path=os.path.join(fig_path, 'exp_train_dft_test.png'))\n",
    "    model_metrics.loc[len(model_metrics)] = {\n",
    "    'Model': model_name,\n",
    "    'Train_set': 'exp',\n",
    "    'Test_set': 'dft',\n",
    "    'R²': metrics['r2'],\n",
    "    'RMSE': metrics['rmse'],\n",
    "    'MAE': metrics['mae']\n",
    "}\n",
    "    # save models\n",
    "    dft_model.save_model(os.path.join(model_path, f'dft_{model_name}.pkl'))\n",
    "    exp_model.save_model(os.path.join(model_path, f'exp_{model_name}.pkl'))\n",
    "    # save model metrics\n",
    "    model_metrics.to_csv(os.path.join(file_path, f'{model_name}_metrics.csv'), index=False)\n",
    "    # append model metrics to the main metrics dataframe\n",
    "    metrics_df = pd.concat([metrics_df, model_metrics], ignore_index=True)\n",
    "    #################################################\n",
    "    # Feature importance plot\n",
    "    # For models that support feature importance\n",
    "    if model_name in ['LightGBM', 'XGBoost', 'RandomForest', 'ExtraRandomTrees']:\n",
    "        # \n",
    "        print(f\"Plotting feature importance for {model_name} on DFT data:\")\n",
    "        dft_importances_df = plot_feature_importance(dft_model.get_model(), dft_train_X.columns, top_n=10,\n",
    "                            fig_path=os.path.join(fig_path, f'dft_feature_importance.png'))\n",
    "        print(f\"Plotting feature importance for {model_name} on EXP data:\")\n",
    "        exp_importances_df = plot_feature_importance(exp_model.get_model(), exp_train_X.columns, top_n=10,\n",
    "                            fig_path=os.path.join(fig_path, f'exp_feature_importance.png'))  \n",
    "# save metrics to csv\n",
    "metrics_df.to_csv(os.path.join(current_path, 'metrics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
