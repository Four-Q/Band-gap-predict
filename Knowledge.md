# Knowledge

### StandScaler()和Normalizer()区别：
`StandardScaler`和`Normalizer`是两种不同的数据预处理方法，核心区别在于**处理维度和目标**：

1. **处理维度**：  
   - **StandardScaler**：按**列（特征维度）**处理数据，对每个特征独立进行标准化（均值为0，标准差为1）[[1]][[2]][[4]][[5]]。  
   - **Normalizer**：按**行（样本维度）**处理数据，将每个样本的特征向量缩放到单位范数（如L2范数）[[1]][[2]][[4]][[7]]。  

2. **数学方法**：  
   - **StandardScaler**：通过公式 \( X_{\text{scaled}} = \frac{X - \mu}{\sigma} \) 实现，其中 \(\mu\) 是均值，\(\sigma\) 是标准差[[2]][[4]][[5]]。  
   - **Normalizer**：通过公式 \( X_{\text{normalized}} = \frac{X}{\|X\|} \) 实现，其中 \(\|X\|\) 是向量的范数（如L1、L2范数）[[4]][[7]][[9]]。  

3. **适用场景**：  
   - **StandardScaler**：适用于特征间量纲差异大、需消除量纲影响的场景（如PCA、聚类、基于距离的模型）[[2]][[7]][[8]]。  
   - **Normalizer**：适用于需要样本间可比性或特征向量方向更重要的场景（如文本分类、稀疏数据）[[1]][[4]][[7]]。  

4. **核心目标**：  
   - **StandardScaler**：使不同特征分布对齐，减少特征间方差差异的影响[[2]][[8]]。  
   - **Normalizer**：强调样本向量的方向而非绝对值，常用于高维稀疏数据[[4]][[7]]。  

总结：`StandardScaler`关注特征间的标准化，而`Normalizer`关注样本向量的归一化，两者在数据处理维度和目标上存在本质差异。